import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# -----------------------------
# 1. Generate Synthetic Dataset
# -----------------------------
np.random.seed(42)
time_steps = 1000

t = np.arange(time_steps)
data = pd.DataFrame({
    'energy': np.sin(0.02 * t) + np.random.normal(0, 0.05, time_steps),
    'temperature': np.cos(0.015 * t),
    'humidity': np.sin(0.01 * t)
})

# -----------------------------
# 2. Scaling
# -----------------------------
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

# -----------------------------
# 3. Create Sequences
# -----------------------------
def create_sequences(data, seq_len=30):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

X, y = create_sequences(scaled_data)

# Train-Test Split
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# -----------------------------
# 4. Transformer Model
# -----------------------------
inputs = layers.Input(shape=(X_train.shape[1], X_train.shape[2]))

attention = layers.MultiHeadAttention(
    num_heads=4, key_dim=32)(inputs, inputs)

attention = layers.LayerNormalization()(attention + inputs)

ffn = layers.Dense(64, activation='relu')(attention)
ffn = layers.Dense(X_train.shape[2])(ffn)

outputs = layers.GlobalAveragePooling1D()(ffn)

model = models.Model(inputs, outputs)
model.compile(
    optimizer='adam',
    loss='mse'
)

# -----------------------------
# 5. Train Model
# -----------------------------
history = model.fit(
    X_train, y_train,
    epochs=30,
    batch_size=32,
    validation_split=0.1,
    verbose=1
)

# -----------------------------
# 6. Evaluation
# -----------------------------
predictions = model.predict(X_test)

mae = mean_absolute_error(y_test, predictions)
rmse = np.sqrt(mean_squared_error(y_test, predictions))
mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100

print("MAE:", mae)
print("RMSE:", rmse)
print("MAPE:", mape)